{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Customer Churn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A marketing agency has many customers that use their service to produce ads for the client/customer websites. They've noticed that they have quite a bit of churn in clients. They basically randomly assign account managers right now, but want you to create a machine learning model that will help predict which customers will churn (stop buying their service) so that they can correctly assign the customers most at risk to churn an account manager. Luckily they have some historical data, can you help them out? Create a classification algorithm that will help classify whether or not a customer churned. Then the company can test this against incoming data for future customers to predict which customers will churn and assign them an account manager.\n",
    "\n",
    "The data is saved as customer_churn.csv. Here are the fields and their definitions:\n",
    "\n",
    "    Name : Name of the latest contact at Company\n",
    "    Age: Customer Age\n",
    "    Total_Purchase: Total Ads Purchased\n",
    "    Account_Manager: Binary 0=No manager, 1= Account manager assigned\n",
    "    Years: Totaly Years as a customer\n",
    "    Num_sites: Number of websites that use the service.\n",
    "    Onboard_date: Date that the name of the latest contact was onboarded\n",
    "    Location: Client HQ Address\n",
    "    Company: Name of Client Company\n",
    "    \n",
    "Once you've created the model and evaluated it, test out the model on some new data (you can think of this almost like a hold-out set) that your client has provided, saved under new_customers.csv. The client wants to know which customers are most likely to churn given this data (they don't have the label yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/eissa/spark-2.3.1-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Session\n",
    "spark = SparkSession.builder.appName('logregconsult').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data = spark.read.csv('customer_churn.csv',inferSchema=True,\n",
    "                     header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|summary|        Names|              Age|   Total_Purchase|   Account_Manager|            Years|         Num_Sites|            Location|             Company|              Churn|\n",
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|  count|          900|              900|              900|               900|              900|               900|                 900|                 900|                900|\n",
      "|   mean|         null|41.81666666666667|10062.82403333334|0.4811111111111111| 5.27315555555555| 8.587777777777777|                null|                null|0.16666666666666666|\n",
      "| stddev|         null|6.127560416916251|2408.644531858096|0.4999208935073339|1.274449013194616|1.7648355920350969|                null|                null| 0.3728852122772358|\n",
      "|    min|   Aaron King|             22.0|            100.0|                 0|              1.0|               3.0|00103 Jeffrey Cre...|     Abbott-Thompson|                  0|\n",
      "|    max|Zachary Walsh|             65.0|         18026.01|                 1|             9.15|              14.0|Unit 9800 Box 287...|Zuniga, Clark and...|                  1|\n",
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Names',\n",
       " 'Age',\n",
       " 'Total_Purchase',\n",
       " 'Account_Manager',\n",
       " 'Years',\n",
       " 'Num_Sites',\n",
       " 'Onboard_date',\n",
       " 'Location',\n",
       " 'Company',\n",
       " 'Churn']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-1.18.1.zip (5.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.4 MB 19 kB/s  eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: numpy\n",
      "  Building wheel for numpy (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for numpy: filename=numpy-1.18.1-cp36-cp36m-linux_x86_64.whl size=13381811 sha256=9015af30809420226bd1689e01db1be41ea5f6c8e8a8d17382ef82385c2f23be\n",
      "  Stored in directory: /root/.cache/pip/wheels/92/18/20/83339b2576b5911519a6b616d8b4a6df8b14358ba5cd612a0b\n",
      "Successfully built numpy\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.18.1\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feature Vector\n",
    "assembler = VectorAssembler(inputCols=['Age',\n",
    " 'Total_Purchase',\n",
    " 'Account_Manager',\n",
    " 'Years',\n",
    " 'Num_Sites'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            Features|\n",
      "+--------------------+\n",
      "|[42.0,11066.8,0.0...|\n",
      "|[41.0,11916.22,0....|\n",
      "|[38.0,12884.75,0....|\n",
      "|[42.0,8010.76,0.0...|\n",
      "|[37.0,9191.58,0.0...|\n",
      "|[48.0,10356.02,0....|\n",
      "|[44.0,11331.58,1....|\n",
      "|[32.0,9885.12,1.0...|\n",
      "|[43.0,14062.6,1.0...|\n",
      "|[40.0,8066.94,1.0...|\n",
      "|[30.0,11575.37,1....|\n",
      "|[45.0,8771.02,1.0...|\n",
      "|[45.0,8988.67,1.0...|\n",
      "|[40.0,8283.32,1.0...|\n",
      "|[41.0,6569.87,1.0...|\n",
      "|[38.0,10494.82,1....|\n",
      "|[45.0,8213.41,1.0...|\n",
      "|[43.0,11226.88,0....|\n",
      "|[53.0,5515.09,0.0...|\n",
      "|[46.0,8046.4,1.0,...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = assembler.transform(data)\n",
    "output.select('Features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = output.select('features','churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_churn,test_churn = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_churn = LogisticRegression(labelCol='churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_churn_model = lr_churn.fit(train_churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|churn|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[22.0,11254.38,1....|  0.0|[4.42702588388791...|[0.98819113813869...|       0.0|\n",
      "|[26.0,8939.61,0.0...|  0.0|[6.74142582917232...|[0.99882043092100...|       0.0|\n",
      "|[28.0,9090.43,1.0...|  0.0|[1.48615989172726...|[0.81550119361629...|       0.0|\n",
      "|[28.0,11128.95,1....|  0.0|[4.04933728447548...|[0.98286480908116...|       0.0|\n",
      "|[28.0,11245.38,0....|  0.0|[4.07552961859397...|[0.98330039535383...|       0.0|\n",
      "|[29.0,5900.78,1.0...|  0.0|[4.46359509933896...|[0.98861034862007...|       0.0|\n",
      "|[29.0,8688.17,1.0...|  1.0|[2.77291746549093...|[0.94119466826719...|       0.0|\n",
      "|[29.0,9378.24,0.0...|  0.0|[5.07662493726641...|[0.99379777065838...|       0.0|\n",
      "|[29.0,9617.59,0.0...|  0.0|[4.79077765183687...|[0.99176242556087...|       0.0|\n",
      "|[29.0,11274.46,1....|  0.0|[4.29178051747326...|[0.98650408630712...|       0.0|\n",
      "|[29.0,13240.01,1....|  0.0|[6.51331238026179...|[0.99851864021348...|       0.0|\n",
      "|[30.0,6744.87,0.0...|  0.0|[3.99347174557118...|[0.98189811982819...|       0.0|\n",
      "|[30.0,7960.64,1.0...|  1.0|[2.90018457105311...|[0.94785556017331...|       0.0|\n",
      "|[30.0,8403.78,1.0...|  0.0|[6.01256857727745...|[0.99755818430488...|       0.0|\n",
      "|[30.0,8677.28,1.0...|  0.0|[4.52813716004096...|[0.98931463280920...|       0.0|\n",
      "|[30.0,10183.98,1....|  0.0|[2.78350651371409...|[0.94177801238579...|       0.0|\n",
      "|[30.0,10960.52,1....|  0.0|[2.31048385021438...|[0.90974159299952...|       0.0|\n",
      "|[30.0,11575.37,1....|  1.0|[3.83976311280367...|[0.97895377287919...|       0.0|\n",
      "|[30.0,13473.35,0....|  0.0|[2.45539782695396...|[0.92095528844811...|       0.0|\n",
      "|[31.0,7073.61,0.0...|  0.0|[3.62905878868022...|[0.97414506627394...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_sum = fitted_churn_model.summary\n",
    "training_sum.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|              churn|         prediction|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|                612|                612|\n",
      "|   mean|0.16993464052287582|0.12745098039215685|\n",
      "| stddev|0.37588258906480865|0.33375026074249314|\n",
      "|    min|                0.0|                0.0|\n",
      "|    max|                1.0|                1.0|\n",
      "+-------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_sum.predictions.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_labels = fitted_churn_model.evaluate(test_churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|churn|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[25.0,9672.03,0.0...|    0|[4.99768031651118...|[0.99329171002819...|       0.0|\n",
      "|[26.0,8787.39,1.0...|    1|[0.50711218760872...|[0.62412926022166...|       0.0|\n",
      "|[27.0,8628.8,1.0,...|    0|[5.61090564109576...|[0.99635557517024...|       0.0|\n",
      "|[28.0,8670.98,0.0...|    0|[8.19009959093042...|[0.99972269066408...|       0.0|\n",
      "|[28.0,11204.23,0....|    0|[1.65928853730423...|[0.84014247453468...|       0.0|\n",
      "|[29.0,10203.18,1....|    0|[3.79514026668229...|[0.97801447668596...|       0.0|\n",
      "|[29.0,12711.15,0....|    0|[5.55197072810861...|[0.99613519103374...|       0.0|\n",
      "|[29.0,13255.05,1....|    0|[3.82894404353012...|[0.97872970563468...|       0.0|\n",
      "|[30.0,8874.83,0.0...|    0|[3.52977474004461...|[0.97152318095468...|       0.0|\n",
      "|[30.0,10744.14,1....|    1|[1.79117160684230...|[0.85707085887955...|       0.0|\n",
      "|[30.0,12788.37,0....|    0|[2.32872372330625...|[0.91122815109689...|       0.0|\n",
      "|[31.0,5304.6,0.0,...|    0|[4.05573435207506...|[0.98297221365201...|       0.0|\n",
      "|[31.0,5387.75,0.0...|    0|[3.34316038091004...|[0.96588014832199...|       0.0|\n",
      "|[31.0,8829.83,1.0...|    0|[4.45630636271535...|[0.98852798501498...|       0.0|\n",
      "|[31.0,10058.87,1....|    0|[4.64904596382800...|[0.99052000208778...|       0.0|\n",
      "|[31.0,12264.68,1....|    0|[3.39735449685123...|[0.96762175442230...|       0.0|\n",
      "|[32.0,8011.38,0.0...|    0|[2.35835987740259...|[0.91359642530536...|       0.0|\n",
      "|[32.0,8575.71,0.0...|    0|[4.05362981531111...|[0.98293695242296...|       0.0|\n",
      "|[32.0,10716.75,0....|    0|[4.65853325526919...|[0.99060867563876...|       0.0|\n",
      "|[32.0,11715.72,0....|    0|[3.43803501374779...|[0.96887230886359...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_and_labels.predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                           labelCol='churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = churn_eval.evaluate(pred_and_labels.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7158641753503414"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on brand new unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr_model = lr_churn.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_customers = spark.read.csv('new_customers.csv',inferSchema=True,\n",
    "                              header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_customers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new_customers = assembler.transform(new_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_new_customers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = final_lr_model.transform(test_new_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+\n",
      "|         Company|prediction|\n",
      "+----------------+----------+\n",
      "|        King Ltd|       0.0|\n",
      "|   Cannon-Benson|       1.0|\n",
      "|Barron-Robertson|       1.0|\n",
      "|   Sexton-Golden|       1.0|\n",
      "|        Wood LLC|       0.0|\n",
      "|   Parks-Robbins|       1.0|\n",
      "+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_results.select('Company','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
